{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1F8maUB146-0aKx8h0ewdZTaVrI962V-9","timestamp":1750111138894}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<table style=\"margin: auto; background-color: white;\">\n","    <tr>\n","      <td style=\"background-color: white;\">\n","        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n","      </td>\n","      <td style=\"background-color: white;\">\n","        <img src='https://drive.google.com/uc?export=view&id=1R6PphT9jmd2vikODFPf6cW54QtZ29o2a' alt=\"drawing\" width=\"200\" />\n","      </td>\n","      <td style=\"background-color: white;\">\n","        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n","      </td>\n","      <td style=\"background-color: white;\">\n","        <img src='https://drive.google.com/uc?export=view&id=1R6PphT9jmd2vikODFPf6cW54QtZ29o2a' alt=\"drawing\" width=\"200\" />\n","      </td>\n","      <td style=\"background-color: white;\">\n","        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n","      </td>\n","      <td style=\"background-color: white;\">\n","        <img src='https://drive.google.com/uc?export=view&id=1R6PphT9jmd2vikODFPf6cW54QtZ29o2a' alt=\"drawing\" width=\"200\" />\n","      </td>\n","      <td style=\"background-color: white;\">\n","        <img src='https://drive.google.com/uc?export=view&id=1lgflViz1uefcvVW1iI57haB4M1bKsZtp' alt=\"drawing\" width=\"200\" />\n","      </td>\n","    </tr>\n","</table>"],"metadata":{"id":"XqLZVV10-uOY"}},{"cell_type":"markdown","source":["#TUTORIAL 2\n","\n","Bem-vindo! Neste tutorial você aprenderá sobre a interface de programação da plataforma **Flautim** e também como montar um experimento simples de classificação usando o dataset [BOSTON](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html).\n","\n","O código desse tutorial pode ser acessado em: [clique aqui.](https://github.com/FutureLab-DCC/flautim_tutoriais/tree/main/TUTORIAL_1)\n","\n","\n","Vamos começar entendendo a interface de programação da **Flautim**, representada na figura abaixo. A **Flautim_api** é uma biblioteca modularizada que facilita a realização de experimentos de aprendizado de máquina, seja convencional/centralizado ou federado.\n","\n","Todo projeto **Flautim** precisa herdar essa biblioteca, que contém submódulos específicos para diferentes tecnologias (por exemplo, submódulos para PyTorch, TensorFlow, etc). Neste tutorial usaremos o submódulo para PyTorch.\n","\n","<div style=\"text-align: center;\"> <table style=\"margin: auto;\"> <tr> <td> <img src='https://drive.google.com/uc?export=view&id=1QOI4jWrwS979xhW_wlGzkPa2bMA-giuc' alt=\"Interface da plataforma Flautim\" width=\"800\" /> </td> </tr> </table> </div>\n","\n","\n","Dentro de cada submódulo existem três componentes principais (classes):\n","\n","**1. Dataset:** é utilizado para representar os dados do experimento. Esta classe pode ser reutilizada em diversos experimentos e com diferentes modelos, sendo o componente mais versátil e reutilizável. Os usuários podem importar os dados de diversas fontes, como arquivos locais ou bases de dados online, desde que a classe Dataset seja herdada.\n","\n","**2. Model:** representa qualquer conjunto de parâmetros treináveis dentro do projeto. Ela permite a aplicação de técnicas de aprendizado de máquina por meio de treinamento desses parâmetros. No caso de PyTorch, a classe herda a nn.Module, que define a estrutura e os parâmetros treináveis do modelo.\n","\n","**3. Experiment:** define o ciclo de treinamento e validação. Existem dois tipos principais de experimentos: o experimento centralizado, que segue o fluxo\n","convencional de aprendizado de máquina, e o experimento federado, adaptado para\n","aprendizado federado. Esta classe inclui duas funções principais, um loop de\n","treinamento e um loop de validação, que realizam a atualização dos parâmetros e\n","cálculo das métricas de custo, respectivamente.\n","\n","Além desses três componentes principais, há também um módulo chamado Common. Este módulo fornece acesso a classes essenciais para o gerenciamento de dados e monitoramento do treinamento.\n","\n","\n","Com essa visão geral, você está pronto para começar montar seus próprios experimentos. Vamos ao passo a passo!"],"metadata":{"id":"5HacTzoG_xm8"}},{"cell_type":"markdown","source":["###Passo 1: Criando o dataset que será usado no experimento\n","\n","Um conjunto de dados no Flautim é acessado por um arquivo .py que deve conter uma classe que herda de Dataset.\n","\n","**Exemplo: Implementando a Classe BostonDataset**\n","\n","O código abaixo implementa uma classe IRISDataset utilizando o dataset IRIS para resolver um problema de classificação."],"metadata":{"id":"ChJrIZCYeTeA"}},{"cell_type":"code","source":["from flautim.pytorch.Dataset import Dataset\n","import torch\n","import copy\n","import flautim as fl\n","\n","class BostonDataset(Dataset):\n","\n","    def __init__(self, file, **kwargs):\n","        super(BostonDataset, self).__init__(name = \"Boston\", **kwargs)\n","\n","        # Defina o que são features e targets\n","        self.features = file.iloc[:, 0:13].values\n","        self.target = file.iloc[:, 13].values\n","\n","        # Número de amostras para teste\n","        self.test_size = int(0.2 * len(file))\n","\n","        # Defina o tipo do tensor de entrada e de saída.\n","        self.xdtype = torch.float32\n","        self.ydtype = torch.float32\n","\n","        # batch_size\n","        self.batch_size = 10\n","\n","        # shuffle\n","        self.shuffle = True\n","\n","        # num_workers\n","        self.num_workers = 1\n","\n","    def train(self) -> Dataset:\n","        # Separação das amostras para treino\n","        train = copy.deepcopy(self)\n","        train.features = self.features[:-self.test_size]\n","        train.target = self.target[:-self.test_size]\n","        return copy.deepcopy(train)\n","\n","    def validation(self) -> Dataset:\n","        # Separação das amostras para validação\n","        test = copy.deepcopy(self)\n","        test.features = self.features[-self.test_size:]\n","        test.target = self.target[-self.test_size:]\n","        return copy.deepcopy(test)\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.features[idx], dtype=torch.float32), torch.LongTensor([self.target[idx]])"],"metadata":{"id":"Hz5LGFkzc9CW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Passo 2: Criando o modelo que será usado no experimento\n","\n","Agora, vamos criar a classe que implementa o modelo. Essa classe deve herdar da classe Model.\n","\n","\n","**Exemplo: Implementando a Classe BostonModel**\n","\n","A classe BostonModel implementa uma rede neural com 4 entradas e 3 saídas."],"metadata":{"id":"6EbqONNwmV3X"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"X51g0zkU-ikV"},"outputs":[],"source":["from flautim.pytorch.Model import Model\n","import torch\n","\n","class BostonModel(Model):\n","    def __init__(self, context, num_classes = 13, **kwargs):\n","        super(BostonModel, self).__init__(context, name = \"BOSTON-NN\", **kwargs)\n","\n","        # Rede neural com 13 entradas e 1 saída\n","        self.c1 = torch.nn.Linear(13, 10)\n","        self.c2 = torch.nn.Linear(10, 5)\n","        self.c3 = torch.nn.Linear(5, 1)\n","\n","\n","    def forward(self, x):\n","        x = torch.relu(self.c1(x))\n","        x = torch.relu(self.c2(x))\n","        x = torch.relu(self.c3(x))\n","        return x"]},{"cell_type":"markdown","source":["###Passo 3: Criando o experimento\n","\n","Por fim, será criado o experimento, isto é, uma classe que implementa os loops de treinamento e validação do modelo BostonModel no dataset BostonDataset. Para isso, precisamos criar dois arquivos .py, o run.py (que deve ter obrigatoriamente esse nome) e o .py responsável por implementar o experimento, descritos a seguir:\n","\n","**1. Arquivo run.py:**\n","\n","* Esse arquivo é o ponto de entrada de todo experimento Flautim, pois é ele\n","que deve iniciar a classe do experimento e também um modelo e um Dataset.\n","\n","**2. Arquivo .py do experimento:**\n","\n","* Esse arquivo deve conter uma classe que implemente os métodos de treinamento (training_loop) e validação (evaluation_loop) do modelo. Essa classe deve herdar da classe Experiment.\n","\n","Esse tutorial cobrirá dois tipos de experimentos, um experimento centralizado e outro descentralizado. Portanto, o passo 3 será dividido entre esses dois cenários."],"metadata":{"id":"_TF_5DkrmXwb"}},{"cell_type":"markdown","source":["####Passo 3.1: Experimento centralizado\n","\n","**Implementando a Classe BostonExperiment**\n","\n","No código abaixo, a classe BostonExperiment foi criada no modo centralizado com seus métodos training_loop e evaluation_loop para treinar e testar a rede neural. Esses métodos retornam o valor da função de perda e a acurácia de treinamento e de validação."],"metadata":{"id":"pnc_5yyYxJUp"}},{"cell_type":"code","source":["from flautim.pytorch.centralized.Experiment import Experiment\n","import flautim as fl\n","import numpy as np\n","import torch\n","import time\n","import torchmetrics\n","\n","class BostonExperiment(Experiment):\n","    def __init__(self, model, dataset, context, **kwargs):\n","        super(BostonExperiment, self).__init__(model, dataset, context, **kwargs)\n","\n","        self.criterion = torch.nn.MSELoss()\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n","        self.epochs = kwargs.get('epochs', 30)\n","        self.mape = torchmetrics.SymmetricMeanAbsolutePercentageError().to(self.context.device)\n","\n","    def training_loop(self, data_loader):\n","        self.model.train()\n","        error_loss = 0.0\n","        yhat, y_real = [], []\n","\n","        for X, y in data_loader:\n","            self.optimizer.zero_grad()\n","            outputs = self.model(X)\n","            loss = self.criterion(outputs, y)\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            error_loss += loss.cpu().item()\n","            yhat.append(outputs.detach().cpu())\n","            y_real.append(y.detach().cpu())\n","\n","        yhat_tensor = torch.cat(yhat)\n","        y_real_tensor = torch.cat(y_real)\n","        mape_value = self.mape(yhat_tensor, y_real_tensor).item()\n","\n","        error_loss = error_loss / len(data_loader)\n","\n","        return float(error_loss), {'MAPE': mape_value}\n","\n","    def validation_loop(self, data_loader):\n","        self.model.eval()\n","        error_loss = 0.0\n","        yhat, y_real = [], []\n","\n","        with torch.no_grad():\n","            for X, y in data_loader:\n","                outputs = self.model(X)\n","                error_loss += self.criterion(outputs, y).item()\n","                yhat.append(outputs.detach().cpu())\n","                y_real.append(y.detach().cpu())\n","\n","        yhat_tensor = torch.cat(yhat)\n","        y_real_tensor = torch.cat(y_real)\n","        mape_value = self.mape(yhat_tensor, y_real_tensor).item()\n","\n","        error_loss = error_loss / len(data_loader)\n","\n","        return float(error_loss), {'MAPE': mape_value}"],"metadata":{"id":"md90drlNmZqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Implementando o run.py para realização de um experimento centralizado**\n","\n","**1. Upload do Conjunto de Dados:**\n","\n","* *Arquivo Local:* Se o seu conjunto de dados for um arquivo (por exemplo, CSV, NPZ, etc.), faça o upload para a plataforma e carregue-o usando o caminho ./data/nomedoarquivo.\n","\n","* *URL:* Se o conjunto de dados estiver disponível em uma URL, inclua a URL no seu código e carregue-o diretamente.\n","\n","**2. Crie uma instância para BostonDataset, BostonModel, BostonExperiment.**\n","\n","**3. Execute as funções:**\n","\n","* ***experiment.run:*** Executa o experimento centralizado."],"metadata":{"id":"mrnii3iLxx1s"}},{"cell_type":"code","source":["import flautim as fl\n","import BOSTONDataset, BOSTONModel, BOSTONExperiment\n","import pandas as pd\n","import numpy as np\n","import flautim.metrics as flm\n","import torch\n","import torchmetrics\n","\n","if __name__ == '__main__':\n","    # Inicializa o contexto do experimento\n","    context = fl.init()\n","\n","    fl.log(\"Flautim2 inicializado!!!\")\n","\n","    # Carrega e embaralha os dados\n","    df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/refs/heads/master/BostonHousing.csv\")\n","    file = df.astype('float32').sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","    dataset = BOSTONDataset.BostonDataset(file, batch_size=10, shuffle=False, num_workers=0)\n","    model = BOSTONModel.BostonModel(context)\n","    experiment = BOSTONExperiment.BostonExperiment(model, dataset, context)\n","\n","    # Métrica MAPE usando torchmetrics (Simétrica)\n","    def mape(y, y_hat):\n","        y = torch.tensor(y)\n","        y_hat = torch.tensor(y_hat)\n","        metric = torchmetrics.SymmetricMeanAbsolutePercentageError()\n","        return metric(y_hat, y).item()\n","\n","    # Registra as métricas no módulo flautim\n","    flm.Metrics.mape = mape\n","\n","    experiment.run(metrics={'MAPE': flm.Metrics.mape})"],"metadata":{"id":"F19b12aGxxTC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Passo 3.2: Experimento federado\n","**Implementando a Classe IRISExperiment**\n","\n","No código abaixo, criamos a classe IRISExperiment no modo federado com seus métodos training_loop e evaluation_loop para treinar e testar a rede neural. Esses métodos retornam o valor da função de perda e a acurácia de treinamento e de validação."],"metadata":{"id":"AEABgvWrGxNN"}},{"cell_type":"code","source":["#Chamar flautim.pytorch.federated.Experiment para experimento federado\n","from flautim.pytorch.federated.Experiment import Experiment\n","import flautim.metrics as flm\n","import flautim as fl\n","import numpy as np\n","import torch\n","import time\n","import torchmetrics\n","\n","class BostonExperiment(Experiment):\n","    def __init__(self, model, dataset, context, **kwargs):\n","        super(BostonExperiment, self).__init__(model, dataset, context, **kwargs)\n","\n","        self.criterion = torch.nn.MSELoss()\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n","        self.epochs = kwargs.get('epochs', 30)\n","\n","    # Definindo métrica\n","    def mape(y_true, y_pred):\n","        y_true = np.asarray(y_true)\n","        y_pred = np.asarray(y_pred)\n","        mask = y_true != 0\n","        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else float('inf')\n","\n","    # Register the new metric\n","    flm.Metrics.mape = mape\n","\n","    def training_loop(self, data_loader):\n","        self.model.train()\n","        error_loss = 0.0\n","        yhat, y_real = [], []\n","\n","        for X, y in data_loader:\n","            self.optimizer.zero_grad()\n","            outputs = self.model(X)\n","            loss = self.criterion(outputs, y)\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            error_loss += loss.cpu().item()\n","            yhat.append(outputs.detach().cpu())\n","            y_real.append(y.detach().cpu())\n","\n","\n","        mape_score = flm.Metrics.mape(torch.cat(y_real).numpy(), torch.cat(yhat).numpy())\n","\n","        error_loss = error_loss / len(data_loader)\n","\n","        return float(error_loss), {'MAPE': mape_value}\n","\n","    def validation_loop(self, data_loader):\n","        self.model.eval()\n","        error_loss = 0.0\n","        yhat, y_real = [], []\n","\n","        with torch.no_grad():\n","            for X, y in data_loader:\n","                outputs = self.model(X)\n","                error_loss += self.criterion(outputs, y).item()\n","                yhat.append(outputs.detach().cpu())\n","                y_real.append(y.detach().cpu())\n","\n","        mape_score = flm.Metrics.mape(torch.cat(y_real).numpy(), torch.cat(yhat).numpy())\n","\n","        error_loss = error_loss / len(data_loader)\n","\n","        return float(error_loss), {'MAPE': mape_value}"],"metadata":{"id":"zCOysvCsG5qL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Implementando o run.py para realização de um experimento federado**\n","\n","**1. Upload do Conjunto de Dados:**\n","\n","* *Arquivo Local:* Se o seu conjunto de dados for um arquivo (por exemplo, CSV, NPZ, etc.), faça o upload para a plataforma e carregue-o usando o caminho ./data/nomedoarquivo.\n","\n","* *URL:* Se o conjunto de dados estiver disponível em uma URL, inclua a URL no seu código e carregue-o diretamente.\n","\n","**2. Separação dos dados por cliente:**\n","\n","* Para simular 4 clientes, divida os dados em 4 partes.\n","\n","**3. Crie uma instância para IRISDataset, IRISModel, IRISExperiment.**\n","\n","**4. Execute as funções:**\n","* ***generate_server_fn:*** Cria a estratégia para o aprendizado federado\n","* ***generate_client_fn:*** Gera o modelo e o dataset de cada cliente.\n","* ***evaluate_fn:*** Avalia o modelo global usando o dataset de um dos clientes.\n","* ***run_federated:*** Executa o experimento federado."],"metadata":{"id":"QO279cKP1BNb"}},{"cell_type":"code","source":["from flautim.pytorch.common import run_federated, weighted_average\n","from flautim.pytorch import Model, Dataset\n","from flautim.pytorch.federated import Experiment\n","import BOSTONDataset, BOSTONModel, BOSTONExperiment\n","import flautim as fl\n","import flwr\n","from flwr.common import Context, ndarrays_to_parameters\n","from flwr.server import ServerConfig, ServerAppComponents\n","import pandas as pd\n","import numpy as np\n","\n","\n","def fit_config(server_round: int):\n","    \"\"\"Return training configuration dict for each round.\n","\n","    Perform two rounds of training with one local epoch, increase to two local\n","    epochs afterwards.\n","    \"\"\"\n","    config = {\n","        \"server_round\": server_round,  # The current round of federated learning\n","    }\n","    return config\n","\n","\n","\n","def generate_server_fn(context, eval_fn, **kwargs):\n","\n","    def create_server_fn(context_flwr:  Context):\n","\n","        net = BOSTONModel.BostonModel(context, suffix = 0)\n","        params = ndarrays_to_parameters(net.get_parameters())\n","\n","        strategy = flwr.server.strategy.FedAvg(\n","                          initial_parameters=params,\n","                          evaluate_metrics_aggregation_fn=weighted_average,\n","                          fraction_fit=0.2,  # 10% clients sampled each round to do fit()\n","                          fraction_evaluate=0.5,  # 50% clients sample each round to do evaluate()\n","                          evaluate_fn=eval_fn,\n","                          on_fit_config_fn = fit_config,\n","                          on_evaluate_config_fn = fit_config\n","                          )\n","        num_rounds = 20\n","        config = ServerConfig(num_rounds=num_rounds)\n","\n","        return ServerAppComponents(config=config, strategy=strategy)\n","    return create_server_fn\n","\n","def generate_client_fn(context, files):\n","\n","    def create_client_fn(context_flwr:  Context):\n","\n","        cid = int(context_flwr.node_config[\"partition-id\"])\n","        file = int(cid)\n","        model = BOSTONModel.BostonModel(context, suffix = cid)\n","        dataset = BOSTONDataset.BostonDataset(files[file], batch_size = 10, shuffle = False, num_workers = 0)\n","\n","        return BOSTONExperiment.BostonExperiment(model, dataset, context).to_client()\n","\n","    return create_client_fn\n","\n","\n","def evaluate_fn(context, files):\n","    def fn(server_round, parameters, config):\n","        \"\"\"This function is executed by the strategy it will instantiate\n","        a model and replace its parameters with those from the global model.\n","        The, the model will be evaluate on the test set (recall this is the\n","        whole MNIST test set).\"\"\"\n","\n","        model = BOSTONModel.BostonModel(context, suffix = \"FL-Global\")\n","        model.set_parameters(parameters)\n","\n","        dataset = BOSTONDataset.BostonDataset(files[0], batch_size = 10, shuffle = False, num_workers = 0)\n","\n","        experiment = BOSTONExperiment.BostonExperiment(model, dataset, context)\n","\n","        config[\"server_round\"] = server_round\n","\n","        loss, _, return_dic = experiment.evaluate(parameters, config)\n","\n","        return loss, return_dic\n","\n","    return fn\n","\n","if __name__ == '__main__':\n","\n","    context = fl.init()\n","    fl.log(f\"Flautim2 inicializado!!!\")\n","\n","    num_clientes = 2\n","\n","    boston = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/refs/heads/master/BostonHousing.csv\")\n","    files = np.random.permutation(boston.astype('float32'))\n","\n","    client_fn_callback = generate_client_fn(context, files)\n","    evaluate_fn_callback = evaluate_fn(context, files)\n","    server_fn_callback = generate_server_fn(context, eval_fn = evaluate_fn_callback)\n","\n","    run_federated(client_fn_callback, server_fn_callback)"],"metadata":{"id":"25KUsCbg07mp"},"execution_count":null,"outputs":[]}]}